
setwd("C:/Users/stephen.roecker/OneDrive - USDA/data/nasis-pedons")
sp <- file.path("C:/Users/stephen.roecker/USDA/NRCS - Soil and Plant Science Division - Point-Data-QC-QA/projects/fy23_groups-overlaps")


library(sf)
library(units)


# load sites ----
s <- read.csv("nasis-sites_20221103.csv")
s$id <- 1:nrow(s)

s <- read.csv("nasis-sites_20221117.csv")
s$id <- 1:nrow(s)

# s3 <- merge(s2, s[c("id", "ID")], by = "ID", all.x = TRUE, sort = FALSE)
# s3$ID <- NULL
# 
# s <- s3[!is.na(s3$id), ]


# load(file = "nat_sites_20220712.RData")


## parse usiteid & upedonid ----

ssa <- soilDB::get_legend_from_SDA(WHERE = "areasymbol LIKE '%'")

co <- sf::read_sf(
  dsn = "D:/geodata/government_units/cb_2021_us_all_500k.gdb", 
  layer = "cb_2021_us_county_500k"
)
fip <- paste0(co$STUSPS, formatC(co$COUNTYFP, width = 3, flag = "0"))

st1 <- sort(unique(substr(ssa$areasymbol, 1, 2)))
st2 <- sort(unique(substr(fip, 1, 2)))
st  <- sort(unique(st1, st2))

p <- paste0(st, "[[:digit:]]{3}", collapse = "|")

idx <- regexpr(p, s$usiteid)
s2  <- s[idx > 0, c("id", "usiteid")]
idx <- idx[idx > 0]

s2$usiteid_fip  <- sapply(1:nrow(s2), function(i) substr(s2$usiteid[i],  idx[i], idx[i] + 4))
s2$usiteid_ssa  <- sapply(1:nrow(s2), function(i) substr(s2$usiteid[i],  idx[i], idx[i] + 4))

idx <- regexpr(p, s$upedonid)
s3  <- s[idx > 0, c("id", "upedonid")]
idx <- idx[idx > 0]

s3$upedonid_fip <- sapply(1:nrow(s3), function(i) substr(s3$upedonid[i], idx[i], idx[i] + 4))
s3$upedonid_ssa <- sapply(1:nrow(s3), function(i) substr(s3$upedonid[i], idx[i], idx[i] + 4))

vars <- c("id", "usiteid_fip", "usiteid_ssa", "upedonid_fip", "upedonid_ssa")
s <- merge(s, s2[-2], by = "id", all.x = TRUE, sort = FALSE) |>
  merge(y = s3[-2], by = "id", all.x = TRUE, sort = FALSE)


# format coordinates ----
s <- within(s, {
    utm            = complete.cases(utmnorthing, utmeasting)
    xy             = complete.cases(x, y)
    utm_zone       = complete.cases(utmnorthing, utmeasting, utmzone)
    utm_zone_datum = complete.cases(utmnorthing, utmeasting, utmzone, horizdatnm)     
    xy_datum       = complete.cases(x, y, horizdatnm)
    xy_std         = complete.cases(x_std, y_std)
    xy_std_mis     = !xy_std
    
    # source
    source = NA
    source = ifelse(utm,            "utm",            source)
    source = ifelse(xy,             "xy",             source)
    source = ifelse(utm_zone,       "utm+zone",       source)
    source = ifelse(utm_zone_datum, "utm+zone+datum", source)     
    source = ifelse(xy_datum,       "xy+datum",       source)
    source = ifelse(xy_std,         "xy_std",         source)
    source = factor(source, levels = c("xy_std", "xy+datum", "utm+zone+datum", "utm+zone", "xy", "utm"))
    
    year = as.integer(substr(obsdate, 1, 4))
  })

test <- aggregate(cbind(utm, xy, utm_zone, utm_zone_datum, xy_datum, xy_std, xy_std_mis) ~ year, data = s, FUN = function(x) sum(x, na.rm = TRUE), na.action = na.pass)

vars <- c("utm", "xy", "utm_zone", "utm_zone_datum", "xy_datum", "xy_std")
# vars <- c("xy_std", "xy_std_mis")
# vars <- "horizdatnm"
test2 <- reshape(
  test[c("year", vars)],
  direction = "long",
  timevar = "variable", times = vars,
  v.names = "value", varying = vars,
  )

ggplot(test2, aes(x = year, y = value, col = variable)) + 
  geom_line(size = 1) + 
  xlim(1950, 2023)

s$test <- !is.na(s$horizdatnm)
test2 <- aggregate(test ~ year + horizdatnm, data = s2, FUN = function(x) sum(x, na.rm = TRUE), na.action = na.pass)

ggplot(test2, aes(x = year, y = test, col = horizdatnm)) + 
  geom_line(size = 1) + 
  xlim(1950, 2023)


table(s2$source, useNA = "always")



## reproject ----

s3 <- within(s, {
  horizdatnm = ifelse(is.na(horizdatnm) & year <  2010 |  utm, "NAD83", horizdatnm)
  horizdatnm = ifelse(is.na(horizdatnm) & year >= 2010 | !utm, "WGS84", horizdatnm)
})


### utm ----  
idx <- s3$xy_std & s3$utm_zone & s3$utmzone < 19
s_utm <- s3[idx, ]
s_utm <- {
  split(s_utm, list(s_utm$utmzone)) ->.;
  lapply(., function(x) {
    temp <- st_as_sf(
      x,
      coords = c("utmeasting", "utmnorthing"),
      crs = as.integer(paste0("269", formatC(x$utmzone[1], width = 2, flag = "0")))
    )
    temp <- st_transform(temp, crs = 4326)
    xy <- st_coordinates(temp)
    colnames(xy) <- c("x_utm", "y_utm")
    temp <- cbind(temp[c("id", "siteiid")], xy)
    st_drop_geometry(temp)
  }) ->.;
  do.call("rbind", .)
}


### latlong DMS ----
idx <- s3$xy_std & s3$xy
s_dms <- s3[idx, ]
s_dms <- {
  split(s_dms, list(s_dms$horizdatnm)) ->.;
  lapply(., function(x) {
    temp <- st_as_sf(
      x,
      coords = c("x", "y"),
      crs = paste0("+proj=longlat +datum=", x$horizdatnm[1], " +no_defs")
    )
    temp <- st_transform(temp, crs = 4326)
    xy <- st_coordinates(temp)
    colnames(xy) <- c("x_dms", "y_dms")
    temp <- cbind(temp[c("id", "siteiid")], xy)
    st_drop_geometry(temp)
  }) ->.;
  do.call("rbind", .)
}


s <- merge(s, s_utm[-2], by.x = "id", all.x = TRUE, sort = TRUE) |>
  merge(y = s_dms[-2],  by.x = "id", all.x = TRUE, sort = TRUE)



##  compare precision ----
s2 <- s
s2 <- within(s2, {
  xy_dms = complete.cases(x_dms, y_dms)
  xy_utm = complete.cases(x_utm, y_utm)
})

idx <- with(s2, (xy_std & xy_dms) | (xy_std & xy_utm))
xy_vars <- c("x_std", "y_std", "x_dms", "y_dms", "x_utm", "y_utm")
s3   <- s2[idx, c("id", xy_vars)]

# df <- with(s3, data.frame(x_std, x_dms, x_utm))

coord_precision <- function(df, std_var, digits) {
  rowSums(round(df, digits), na.rm = TRUE) == round(df[[std_var]], digits) * rowSums(!is.na(df))
}

idx <- c(1, 3, 5)
s3$x_w001m <- coord_precision(s3[xy_vars[idx]], xy_vars[1], 5)
s3$x_w011m <- coord_precision(s3[xy_vars[idx]], xy_vars[1], 4)
s3$x_w111m <- coord_precision(s3[xy_vars[idx]], xy_vars[1], 3)

idx <- c(2, 4, 6)
s3$y_w001m <- coord_precision(s3[xy_vars[idx]], xy_vars[2], 5)
s3$y_w011m <- coord_precision(s3[xy_vars[idx]], xy_vars[2], 4)
s3$y_w111m <- coord_precision(s3[xy_vars[idx]], xy_vars[2], 3)


xy_pr <- names(s3)[grepl("x_w|y_w", names(s3))]
summary(s3[xy_pr])

s4 <- merge(s, s3[c("id", xy_pr)], by = "id", all.x = TRUE, sort = FALSE)
# write.csv(s4, file = "nasis-sites_20221117_xy-converted.csv", row.names = FALSE)
s42 <- read.csv(file = "nasis-sites_20221117_xy-converted.csv")

## promote to sf ----
s2 <- merge(s2, s3[c("id", xy_pr)], by = "id", all.x = TRUE, sort = FALSE)
s_xy <- s2[s2$xy_std | s2$xy_dms | s2$xy_utm, ]

xy_l <- list(c("x_std", "y_std"), c("x_dms", "y_dms"), c("x_utm", "y_utm"))

s_l <- lapply(xy_l, function(i) {
  idx <- complete.cases(s_xy[i])
  temp <- s_xy[idx, ]
  
  sf <- st_as_sf(
    temp,
    coords = i,
    crs = 4326
  )
})
# save(s_l, file = "s_l_20221117.RData")
load(file = "s_l_20221117.RData")


## export as .gpkg ----
idx <- which(sapply(s_sf, is.logical))
# .gpkg don't like factors or logicals
s_sf[idx] <- lapply(st_drop_geometry(s_sf[idx]), as.character)

format(Sys.time(), "%H:%M:%S")
write_sf(s_sf, dsn = "nasis_sites_20221021.gpkg")
format(Sys.time(), "%H:%M:%S")

write.csv(s_sf["peiid"], file = "test.csv", row.names = TRUE)


# intersect overlaps ----
## MLRA ----

mlra42 <- read_sf("D:/geodata/soils/mlra_v42.shp") |>
  st_transform(4326) |>
  # rmapshaper::ms_simplify() |>
  # rmapshaper::ms_dissolve(field = "MLRARSYM") |>
  st_make_valid()

mlra52 <- read_sf("D:/geodata/soils/MLRA_52.shp") |>
  st_transform(4326) |>
  # rmapshaper::ms_simplify() |>
  st_make_valid()


s_l_mlra <- lapply(s_l, function(x) {
  
  cat("getting list \n")
  
  idx42  <- st_intersects(x["id"], mlra42)
  idx421 <- unlist(lapply(idx42, function(x) length(x) > 0))
  s_sub42  <- x[idx421, "id"]
  s_mlra42_gis <- cbind(s_sub42, st_drop_geometry(mlra42[unlist(idx42[idx421]), ]))
  
  
  idx52  <- st_intersects(x["id"], mlra52)
  idx521 <- unlist(lapply(idx52, function(x) length(x) > 0))
  s_sub52  <- x[idx521, "id"]
  s_mlra52_gis <- cbind(s_sub52, st_drop_geometry(mlra52[unlist(idx52[idx521]), ]))
  
  s_mlra_gis <- merge(
    st_drop_geometry(s_mlra42_gis), 
    st_drop_geometry(s_mlra52_gis), 
    by  = c("id"),
    suffixes = c("_42", "_52"),
    all = TRUE
  )
})

vars <- c("dd", "dms", "utm")
names(s_l_mlra) <- vars
for (i in 1:3) {
  names(s_l_mlra[[i]])[-1] <- paste0(vars[i], "_", names(s_l_mlra[[i]])[-1])
}
s_mlra_gis <- merge(
  s_l_mlra[[1]], s_l_mlra[[2]], by = "id", all = TRUE
  ) |>
  merge(y = s_l_mlra[[3]], by = "id", all = TRUE)


# write.csv(s_mlra_gis, file = "s_mlra_gis_20221117.csv", row.names = FALSE)
s_mlra_gis <- read.csv(file = "s_mlra_gis_20221117.csv")



## State & County ----

co <- read_sf(
  dsn = "D:/geodata/government_units/cb_2021_us_all_500k.gdb", 
  layer = "cb_2021_us_county_500k"
  ) |>
  # rmapshaper::ms_simplify() |>
  st_transform(4326)
st_geometry(co) <- "geometry"


# county
s_l_co <- lapply(s_l, function(x) {
  
  cat("getting list \n")
  
  idx <- st_intersects(x["id"], co)
  idx2   <- unlist(lapply(idx, function(x) length(x) > 0))
  s_sub  <- st_drop_geometry(x[idx2, "id"])
  s_co_gis <- cbind(s_sub, st_drop_geometry(co[unlist(idx[idx2]), ]))
})

vars <- c("dd", "dms", "utm")
names(s_l_co) <- vars
for (i in 1:3) {
  names(s_l_co[[i]])[-1] <- paste0(vars[i], "_", names(s_l_co[[i]])[-1])
}
s_co_gis <- merge(
  s_l_co[[1]], s_l_co[[2]], by = "id", all = TRUE
) |>
  merge(y = s_l_co[[3]], by = "id", all = TRUE)

# write.csv(s_co_gis, file = "s_co_gis_20221117.csv", row.names = FALSE)
s_co_gis <- read.csv("s_co_gis_20221117.csv")



## SAPOLYGON ----
sapol <- read_sf(
  dsn = "D:/geodata/soils/gSSURGO_CONUS_202210.gdb", 
  layer = "SAPOLYGON"
  ) |>
  # rmapshaper::ms_simplify() |>
  st_transform(4326)
st_geometry(sapol) <- "geometry"

oconus <- readRDS("D:/geodata/project_data/gsp-gsocseq/sapol_oconus.rds")
oconus <- do.call("rbind", oconus)
oconus <- st_transform(oconus, 4326)
names(oconus)[1:3] <- toupper(names(oconus)[1:3])

vars  <- c("LKEY", "AREASYMBOL", "geometry")
sapol <- rbind(sapol[vars], oconus[vars])
sapol <- st_make_valid(sapol)


s_l_sapol <- lapply(s_l, function(x) {
  
  cat("getting list \n")
  
  idx <- st_intersects(x["id"], sapol)
  idx2   <- unlist(lapply(idx, function(x) length(x) > 0))
  s_sub  <- st_drop_geometry(x[idx2, "id"])
  s_sapol_gis <- cbind(s_sub, st_drop_geometry(sapol[unlist(idx[idx2]), ]))
})

vars <- c("dd", "dms", "utm")
names(s_l_sapol) <- vars
for (i in 1:3) {
  names(s_l_sapol[[i]])[-1] <- paste0(vars[i], "_", names(s_l_sapol[[i]])[-1])
}
s_sapol_gis <- merge(
  s_l_sapol[[1]], s_l_sapol[[2]], by = "id", all = TRUE
) |>
  merge(y = s_l_sapol[[3]], by = "id", all = TRUE)

# write.csv(s_sapol_gis, file = "s_sapol_gis_20221117.csv", row.names = FALSE)
s_sapol_gis <- read.csv("s_sapol_gis_20221117.csv")


# s_sf_sapol <- st_intersection(s_sf, sapol)
# idx <- sapply(s_sf_sapol, is.logical)
# s_sf_sapol[idx] <- lapply(st_drop_geometry(s_sf_sapol[idx]), as.character)
# write_sf(cbind(st_coordinates(s_sf_sapol), s_sf_sapol[c("peiid", "AREASYMBOL")]), dsn = "nasis_sites_20220309.gpkg")


## SSURGO ----

dsn  <- "D:/geodata/soils/gSSURGO_CONUS_202210.gdb"
dsn2 <- "D:/geodata/soils/wss_gsmsoil_US_20161013.gdb"
ssa <- read_sf(dsn, layer = "legend") |>
  dplyr::arrange(areasymbol)
mu  <- read_sf(dsn, layer = "mapunit")


le <- read_sf(dsn, layer = "legend")
st <- sort(unique(substr(le$areasymbol, 1, 2)))
mu_sda <- lapply(st, function(x) {
  cat("getting ", x, "\n")
  get_mapunit_from_SDA(WHERE = paste0("areasymbol LIKE '", x, "%'"))
})
mu_sda <- do.call("rbind", mu_sda)
# write.csv(mu_sda, file = "mu_conus_sda_20221114.csv", row.names = FALSE)
mu_sda <- read.csv("mu_conus_sda_20221114.csv")


mu <- merge(mu, mu_sda[c("mukey", "nationalmusym")], by = "mukey", all.y = TRUE, sort = FALSE)


vars <- c("dd", "dms", "utm")
names(s_l) <- vars
# names(s_l) <- paste0(vars, "_statsgo")

asym <- sort(read_sf(dsn, layer = "legend")$areasymbol)

s_l_mupol <- lapply(1:3, function(i) {
  
  s <- s_l[[i]]
  s <- st_transform(s, crs = 5070)
  
  cat("getting list", names(s_l)[i], "\n")
  
  # temp <- lapply(asym, function(x) {
  temp <- lapply("US", function(x) {
      
    cat("getting ", x, as.character(Sys.time()), "\n")
    
    q <- paste0(
      "
    SELECT *
    FROM MUPOLYGON
    WHERE AREASYMBOL = '",
      x,
      "'"
    )
    
    
    # mupol_x <- read_sf(dsn, query = q) |>
    mupol_x <- read_sf(dsn2, query = q) |>
      st_cast(to = "MULTIPOLYGON") |>
      st_make_valid() |>
      st_transform(crs = 5070) |>
      st_make_valid()

    
    idx_l  <- st_intersects(s["id"], mupol_x)
    idx_0  <- unlist(lapply(idx_l,        function(x) length(x) > 0))
    s_sub  <- st_drop_geometry(s[idx_0, "id"])
    idx_i <- unlist(sapply(idx_l[idx_0], function(x) x[1]))
    s_mupol_gis <- cbind(s_sub, st_drop_geometry(mupol_x[idx_i, ]))
  })
  temp <- do.call("rbind", temp)
  write.csv(temp, file = paste0("s_l_mupol_", names(s_l)[i], "_20221112.csv"), row.names = TRUE)
  return(temp)
})

names(s_l_mupol) <- vars
for (i in 1:3) {
  names(s_l_mupol[[i]])[-1] <- paste0(vars[i], "_", names(s_l_mupol[[i]])[-1])
}
s_mupol_gis <- merge(
  s_l_mupol[[1]], s_l_mupol[[2]], by = "id", all = TRUE
) |>
  merge(y = s_l_mupol[[3]], by = "id", all = TRUE)


# write.csv(s_mupol_gis, file = "s_mupol_ssurgo_gis_20221117.csv", row.names = FALSE)
# write.csv(s_mupol_gis, file = "s_mupol_statsgo_gis_20221117.csv", row.names = FALSE)
s_mupol1_gis <- read.csv("s_mupol_ssurgo_gis_20221117.csv")
s_mupol2_gis <- read.csv("s_mupol_statsgo_gis_20221103.csv")


# replace SSURGO NOTCOM values with STATSGO
s_mupol_gis <- s_mupol1_gis
s_mupol_gis$dd_MUKEY  <- ifelse(s_mupol_gis$dd_MUSYM  == "NOTCOM", s_mupol2_gis$dd_MUKEY,  s_mupol_gis$dd_MUKEY)
s_mupol_gis$dms_MUKEY <- ifelse(s_mupol_gis$dms_MUSYM == "NOTCOM", s_mupol2_gis$dms_MUKEY, s_mupol_gis$dms_MUKEY)
s_mupol_gis$utm_MUKEY <- ifelse(s_mupol_gis$utm_MUSYM == "NOTCOM", s_mupol2_gis$utm_MUKEY, s_mupol_gis$utm_MUKEY)

# write.csv(s_mupol_gis, file = "s_mupol_gis_20221117.csv", row.names = FALSE)
s_mupol_gis <- read.csv("s_mupol_gis_20221117.csv")



# lyrs <- st_layers(dsn)
# n    <- lyrs$features[lyrs$name == "MUPOLYGON"]
# offset <- seq(1, n, 1e6)
# 
# co   <- read_sf(dsn, layer = "component")
# co <- within(co, {
#   compname = tolower(compname)
#   compname = gsub("^ | $|?| family| variant| taxadjunct", "", compname)
#   compname = sapply(compname, function(x) strsplit(x, "\\(|,|-")[[1]][1])
# })


# s_mupol_gis2 <- lapply(offset, function(x) {
#   
#   cat("getting", x, format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "\n")
#   
#   mupol <- read_sf(dsn, query = paste("SELECT * FROM MUPOLYGON LIMIT 1000000 OFFSET", x))
#   
#   idx    <- st_intersects(s_sf, mupol)
#   idx2   <- unlist(lapply(idx, function(x) length(x) > 0))
#   s_sub  <- s_sf[idx2, ]
#   # mupol_sub <- mupol[unlist(idx[idx2]), ]
#   # tmp   <- st_intersection(s_sub, mupol_sub)
#   tmp <- cbind(s_sub, st_drop_geometry(mupol[unlist(idx[idx2]), ]))
#   
#   tmp <- within(tmp, {
#     taxonname_recent = tolower(taxonname_recent)
#     taxonname_recent = gsub("^ | $|?| family| variant| taxadjunct", "", taxonname_recent)
#     taxonname_recent = sapply(taxonname_recent, function(x) strsplit(x, "\\(|,|-")[[1]][1])
#   })
#   
#   idx <- {
#       co$mukey %in% tmp$MUKEY & 
#       co$compname %in% tmp$taxonname_recent &
#       !is.na(co$comppct_r)
#   }
#   
#   tmp$key <- paste(tmp$MUKEY, tmp$taxonname_recent)
#   co$key  <- paste(co$mukey, co$compname)
#   
#   co <- co[order(co$mukey, - co$comppct_r), ]
#   co <- subset(co, !duplicated(paste(mukey, compname)))
#   
#   tmp2 <- merge(
#     tmp[c("peiid", "taxonname_recent", "MUKEY")], 
#     co[c("cokey", "compname", "mukey")],
#     by.x = "MUKEY", by.y = "mukey",
#     all.x = TRUE
#     )
#   tmp2 <- aggregate(peiid ~ mukey, data = tmp2, function(x) list(unique()))
#   
#   # buffered distance
#   # s_buf100 <- st_buffer(s_sub["peiid"], 100)
#   # 
#   # idx    <- st_intersects(s_buf100, mupol)
#   # idx2   <- unlist(lapply(idx, function(x) length(x) > 0))
#   # 
#   # mupol_buf_sub <- mupol[unlist(idx[idx2]), ]
#   # 
#   # s_mupol_buf_gis <- st_intersection(s_buf100, mupol_buf_sub)
#   
#   return(tmp)
# })
# 
# # save(s_mupol_gis2, file = "s_mupol_gis2.RData")
# # s_mupol_gis3 <- do.call("rbind", s_mupol_gis2)
# # 
# # s_mupol_gis <- cbind(st_coordinates(s_mupol_gis3), st_drop_geometry(s_mupol_gis3))
# # write.csv(s_mupol_gis, file = "C:/Users/stephen.roecker/OneDrive - USDA/data/nasis-pedons/s_mupol_gis_20220309.csv", row.names = FALSE)
# 
# s <- read.csv(file = "s_mupol_gis_20220309.csv")



### MLRA ----
crs <- "+proj=aea +lat_0=23 +lon_0=-96 +lat_1=29.5 +lat_2=45.5 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs"

mlra42 <- mlra42 |>
  rmapshaper::ms_simplify() |>
  # rmapshaper::ms_dissolve(field = "MLRARSYM") |
  st_transform(crs = crs)


mlra52 <- mlra52 |>
  rmapshaper::ms_simplify() |>
  st_transform(crs = crs)


mlra_int <- function(dsn, mlra_sf) {
  
  le  <- read_sf(dsn, layer = "legend")
  ssa <- sort(unique(le$areasymbol))
  
  lapply(ssa, function(x) {
  
  cat("getting ", x, as.character(Sys.time()))
  
  q <- paste0(
    "
    SELECT * 
    FROM MUPOLYGON
    WHERE AREASYMBOL = '",
    x,
    "'"
  )
  # q <- "SELECT * FROM MUPOLYGON LIMIT 10 OFFSET 0"
  mupol <- read_sf(dsn, query = q) |>
    st_cast(to = "MULTIPOLYGON") |>
    st_make_valid() # |>
  #   # rmapshaper::ms_simplify()

  temp <- tryCatch(
    st_intersection(mupol, mlra_sf),
    error = function(e) e,
    finally = print("success")
    )
  
  if (is.data.frame(temp)) {
    temp$area <- st_area(temp)
    temp <- aggregate(
      area ~ MUKEY + MLRARSYM, 
      data = st_drop_geometry(temp), 
      FUN = function(x) sum(x, na.rm = TRUE), 
      na.action = na.pass
    )
    units(temp$area) <- make_units(acre)
    names(temp)[3] <- "acres"
  } else temp <- NULL
  return(temp)
})}


# SSURGO
test <- mlra_int(dsn, mlra42)
mupol_mlra42 <- do.call("rbind", test)
# write.csv(mupol_mlra42, file = "mupol_mlra42.csv", row.names = FALSE)
mupol_mlra42 <- read.csv("mupol_mlra42.csv")

test <- mlra_int(mlra52)
mupol_mlra52 <- do.call("rbind", test)
# write.csv(mupol_mlra52, file = "mupol_mlra52.csv", row.names = FALSE)
mupol_mlra52 <- read.csv("mupol_mlra52.csv")


# STATSGO
dsn  <- "D:/geodata/soils/wss_gsmsoil_US_20161013.gdb"
test <- mlra_int(dsn, mlra42)
mupol2_mlra42 <- do.call("rbind", test)
# write.csv(mupol2_mlra42, file = "mupol_statsgo_mlra42.csv", row.names = FALSE)
mupol2_mlra42 <- read.csv("mupol_statsgo_mlra42.csv")

test <- mlra_int(dsn, mlra52)
mupol2_mlra52 <- do.call("rbind", test)
# write.csv(mupol2_mlra52, file = "mupol_statsgo_mlra52.csv", row.names = FALSE)
mupol2_mlra52 <- read.csv("mupol_mlra52.csv")


vars <- c("mukey", "nationalmusym")
idx  <- mu$lkey %in% le$lkey[le$areasymbol == "US"]

mu1_mlra42 <- merge(mu[!idx, vars], mupol_mlra42,  by.x = "mukey", by.y = "MUKEY", all.x = TRUE, sort = FALSE)
mu2_mlra42 <- merge(mu[ idx, vars], mupol2_mlra42, by.x = "mukey", by.y = "MUKEY", all.x = TRUE, sort = FALSE)
mu_mlra42  <- rbind(mu1_mlra42, mu2_mlra42) 

mu1_mlra52 <- merge(mu[!idx, vars], mupol_mlra52,  by.x = "mukey", by.y = "MUKEY", all.x = TRUE, sort = FALSE)
mu2_mlra52 <- merge(mu[ idx, vars], mupol2_mlra52, by.x = "mukey", by.y = "MUKEY", all.x = TRUE, sort = FALSE)
mu_mlra52  <- rbind(mu1_mlra52, mu2_mlra52) 


# calculate dominant MLRA by nationalmusym
mukey_mlra_agg <- function(mu, mlra) {
  mlra %>%
    # mutate(mukey = as.integer(mukey)) %>%
    # left_join(mlra, by = c("mukey" = "MUKEY")) %>%
    group_by(nationalmusym, MLRARSYM) %>%
    summarize(
      acres_sum = sum(acres, na.rm = TRUE),
      mlra_pct = acres / acres_sum
      ) %>%
    ungroup() %>%
    arrange(nationalmusym, - acres_sum) %>%
    filter(!duplicated(nationalmusym)) %>%
    # mutate(acres = NULL) %>%
    right_join(mu, by = "nationalmusym") %>%
    select(mukey, MLRARSYM_dom = MLRARSYM, mlra_pct)
}
  
mukey23_mlra42 <- mukey_mlra_agg(mu, mu_mlra42)
mukey23_mlra52 <- mukey_mlra_agg(mu, mu_mlra52)

# write.csv(mukey23_mlra42, file = "mukey23_mlra42_20221117.csv", row.names = FALSE)
# write.csv(mukey23_mlra52, file = "mukey23_mlra52_20221117.csv", row.names = FALSE)


mukey23_mlra42 <- read.csv(file = "mukey23_mlra42_20221114.csv")
mukey23_mlra52 <- read.csv(file = "mukey23_mlra52_20221114.csv")
names(mukey23_mlra42)[2] <- "mlra42_dom"
names(mukey23_mlra52)[2] <- "mlra52_dom"

mukey23_mlra <- merge(
  mukey23_mlra42[-3],
  mukey23_mlra52[-3],
  by = "mukey",
  # all.x = TRUE,
  sort = FALSE
)


s_mupol_gis <- read.csv("s_mupol_gis_20221117.csv")


vars <- c("id", "dd_MUKEY", "dms_MUKEY", "utm_MUKEY")
# dd
s_mlraC_gis <- merge(s_mupol_gis[vars], mukey23_mlra, by.x = "dd_MUKEY", by.y = "mukey", all.x = TRUE, sort = FALSE)
names(s_mlraC_gis)[5:6] <- paste0("dd_", names(s_mlraC_gis)[5:6])
# dms
s_mlraC_gis <- merge(s_mlraC_gis,      mukey23_mlra, by.x = "dms_MUKEY", by.y = "mukey", all.x = TRUE, sort = FALSE)
names(s_mlraC_gis)[7:8] <- paste0("dms_", names(s_mlraC_gis)[7:8])
# utm
s_mlraC_gis <- merge(s_mlraC_gis,      mukey23_mlra, by.x = "utm_MUKEY", by.y = "mukey", all.x = TRUE, sort = FALSE)
names(s_mlraC_gis)[9:10] <- paste0("utm_", names(s_mlraC_gis)[9:10])

s_mlraC_gis[1:3] <- NULL

write.csv(s_mlraC_gis, file = "s_mukey-mlra_gis_20221117.csv", row.names = FALSE)



### Ecosites ----
eco <- DBI::dbGetQuery(soilDB::NASIS(), "SELECT * FROM ecologicalsite") |>
  soilDB::uncode()
eco$ecosite_mlra <- gsub("^0|^00", "", eco$ecositemlra)
eco$ecosite_mlra <- gsub("X$", "", eco$ecosite_mlra)

s_eco_gis  <- merge(s[c("id", "ecositeid")], eco[c("ecositeid", "ecosite_mlra")], by = "ecositeid", all.x = TRUE, sort = FALSE)
s_eco_gis$ecositeid <- NULL

write.csv(s_eco_gis, file = "s_eco_gis_20221117.csv", row.names = FALSE)



#### coecoclass ----

SDA_query("SELECT TOP(10) * FROM coecoclass")


le <- SDA_query("SELECT * FROM legend")


test <- lapply(sort(le$areasymbol), function(x) {
  
  cat("getting", x, "\n")
  
  SDA_query(paste0(
    "SELECT TOP(10) areasymbol, nationalmusym, mukey cokey, compname, ecoclassid 
  
  FROM 
  coecoclass ce                        INNER JOIN
  component  co ON co.cokey = ce.cokey INNER JOIN
  mapunit    mu ON mu.mukey = co.mukey INNER JOIN
  legend     le ON le.lkey  = mu.lkey
  
  WHERE areasymbol = '", x, "'"))
})
test <- do.call("rbind", test)

test2 <- merge(test, eco, by.x = "ecoclassid", by.y = "ecositeid", all.x = TRUE, sort = FALSE)

test3 <- test2 %>% group_by(areasymbol, nationalmusym) %>% summarize(n = length(unique(ecosite_mlra)))



## PLSS ----
plss <- read_sf(dsn = "D:/geodata/cadastral/PLSS20220926/p20/ilmocplss.gdb", layer = "PLSSFirstDivision") |>
  st_cast(to = "MULTIPOLYGON") |>
  st_make_valid() |>
  st_transform(4326)
st_geometry(plss) <- "geometry"


plss$idx <- substr(plss$PLSSID, 1, 5)
# idx <- sort(unique(plss$idx))
# plss_l <- lapply(idx, function(i) {
#   
#   cat("simplifying ", i, as.character(Sys.time()), "\n")
#   
#   plss_sub <- plss[plss$idx == i, ]
#   
#   tryCatch(
#     rmapshaper::ms_simplify(plss_sub),
#     error = function(e) e,
#     finally = print("success")
#   )}
# )
# 
# # saveRDS(plss_l, file = "D:/geodata/cadastral/PLSS20220926/p20/plss_l.rds")
# plss_l <- readRDS(file = "D:/geodata/cadastral/PLSS20220926/p20/plss_l.rds")
# 
# 
# names(plss_l) <- idx
# idx      <- sapply(plss_l, is.data.frame)
# plss_l2  <- plss_l[idx]
# plss_l2  <- lapply(plss_l2, function(x) st_cast(x, "MULTIPOLYGON"))
# plss_sf  <- dplyr::bind_rows(plss_l2)
# plss_sf  <- st_make_valid(plss_sf)
# 
# plss_mis <- plss[plss$idx %in% names(plss_l)[!idx], ]
# plss_sf  <- dplyr::bind_rows(plss_sf, plss_mis)
# 
# idx <- st_is_valid(plss_sf)
# # plss_sub2 <- st_as_sfc(plss_sub) |>
# #   lwgeom::lwgeom_make_valid() |>
# #   st_as_sf()
# # st_geometry(plss_sub2) <- "geometry"
# # st_geometry(plss_sub) <- plss_sub2
# # plss_sf2 <- rbind(plss_sf[idx, ], plss_sub)
# idx2 <- plss_sf[!idx, ]$FRSTDIVID
# plss_sf2 <- dplyr::bind_rows(
#   plss_sf[idx, ], 
#   plss[plss$FRSTDIVID %in% idx2, ]
#   )
# 
# 
# # saveRDS(plss_sf2, file = "D:/geodata/cadastral/PLSS20220926/p20/plss_sf.rds")
# plss <- readRDS(file = "D:/geodata/cadastral/PLSS20220926/p20/plss_sf.rds")
# 
# 
# s_l2 <- lapply(s_l, function(x) {
#   idx <- complete.cases(x$plsssection, x$plsstownship, x$plssrange)
#   x[idx, ]
# })


s_l_plss <- lapply(s_l, function(s) {
  
  cat("getting list \n")
  
  temp <- by(plss, plss$idx, function(plss_x) {
    
    cat("getting ", plss_x$idx[1], as.character(Sys.time()), "\n")
    
    idx_l  <- st_intersects(s["id"], plss_x)
    idx_0  <- unlist(lapply(idx_l,        function(x) length(x) > 0))
    s_sub  <- st_drop_geometry(s[idx_0, "id"])
    idx_i <- unlist(sapply(idx_l[idx_0], function(x) x[1]))
    s_plss_gis <- cbind(s_sub, st_drop_geometry(plss_x[idx_i, ]))
  })
  do.call("rbind", temp)
})

vars <- c("dd", "dms", "utm")
names(s_l_plss) <- vars
for (i in 1:3) {
  names(s_l_plss[[i]])[-1] <- paste0(vars[i], "_", names(s_l_plss[[i]])[-1])
}
s_plss_gis <- merge(
  s_l_plss[[1]], s_l_plss[[2]], by = "id", all = TRUE
) |>
  merge(y = s_l_plss[[3]], by = "id", all = TRUE)


# write.csv(s_plss_gis, file = "s_plss_gis_20221117.csv", row.names = FALSE)
s_plss_gis <- read.csv("s_plss_gis_20221117.csv")



# merge overlaps ----
setwd("C:/Users/stephen.roecker/OneDrive - USDA/data/nasis-pedons")

s <- read.csv(file = "nasis-sites_20221117_xy-converted.csv")
# s$id <- 1:nrow(s)
s_sapol_gis <- read.csv("s_sapol_gis_20221117.csv")
s_mlra_gis  <- read.csv("s_mlra_gis_20221117.csv")
s_co_gis    <- read.csv("s_co_gis_20221117.csv")
s_plss_gis  <- read.csv("s_plss_gis_20221117.csv")
s_mupol_gis <- read.csv("s_mupol_gis_20221117.csv")
s_mukey_mlra_gis <- read.csv("s_mukey-mlra_gis_20221117.csv")
s_eco_gis   <- read.csv("s_eco_gis_20221117.csv")


s_co_gis <- within(s_co_gis, {
  dd_countyfp  = paste0(dd_STUSPS,  formatC(dd_COUNTYFP,  width = 3, flag = 0))
  dms_countyfp = paste0(dms_STUSPS, formatC(dms_COUNTYFP, width = 3, flag = 0))
  utm_countyfp = paste0(utm_STUSPS, formatC(utm_COUNTYFP, width = 3, flag = 0))
})

so <- merge(
  s[c(1:37, 65:87)],
  s_sapol_gis,
  by = "id",
  all.x = TRUE,
  sort = FALSE
  ) |>
  merge(
    y = s_mlra_gis,
    by = "id",
    all.x = TRUE,
    sort = FALSE
  ) |>
  merge(
    y = s_co_gis[c("id", "dd_countyfp", "dd_STUSPS", "dms_countyfp", "dms_STUSPS", "utm_countyfp", "utm_STUSPS")],
    by = "id",
    all.x = TRUE,
    sort = FALSE
  ) |>
  merge(
    y = s_plss_gis[c("id", "dd_FRSTDIVID", "dms_FRSTDIVID", "utm_FRSTDIVID")],
    by = "id",
    all.x = TRUE,
    sort = FALSE
  ) |>
  merge(
    y = s_mukey_mlra_gis,
    by = "id",
    all.x = TRUE,
    sort = FALSE
    ) |>
  merge(
    y = s_eco_gis,
    by = "id",
    all.x = TRUE,
    sort = TRUE
  )



# QA overlaps ----
so <- subset(so, !duplicated(siteiid))
so2 <- so
so <- within(so, {
  xy = complete.cases(x_std, y_std) | complete.cases(x_dms, y_dms) | complete.cases(x_utm, x_utm)
  n      = 1
  year   = as.integer(format(as.Date(obsdate), "%Y"))
  decade = floor(year * 0.1) * 10
  
  #plss
  dd_plss    = paste0(substr(dd_FRSTDIVID, 5, 20))
  dms_plss   = paste0(substr(dms_FRSTDIVID, 5, 20))
  utm_plss   = paste0(substr(utm_FRSTDIVID, 5, 20))
  
  plsssection  = formatC(plsssection, width = 2, flag = 0)
  
  plsstownship = toupper(plsstownship)
  plssrange    = toupper(plssrange)

  plsstownship = gsub("NORTH|M", "N", plsstownship)
  plsstownship = gsub("SOUTH", "S", plsstownship)
  plssrange    = gsub("WEST",  "W", plssrange)
  plssrange    = gsub("EAST",  "E", plssrange)

  plsstownship = gsub("^T| |\\.|-|`|,|/|>", "", plsstownship)
  plssrange    = gsub("^R| |\\.|-|`|,|/|>", "", plssrange)

  plsstownship = gsub("^0", "", plsstownship)
  plssrange    = gsub("^0", "", plssrange)
  
  plsstownship = gsub("^N|^S", 0, plsstownship) 
  plssrange    = gsub("^W|^E", 0, plssrange) 
  
  plsstownship = ifelse(grepl("^[[:digit:]{1,3}]", plsstownship), plsstownship, NA)
  plssrange    = ifelse(grepl("^[[:digit:]{1,3}]", plssrange),    plssrange,    NA)
  
  idx = regexpr("[NS]", plsstownship)
  plsstownship = paste0(formatC(as.integer(substr(plsstownship, 1, idx - 1)), width = 3, flag = 0), "0", substr(plsstownship, idx, 4))
  idx = regexpr("[WE]", plssrange)
  plssrange    = paste0(formatC(as.integer(substr(plssrange,    1, idx - 1)), width = 2, flag = 0), "0", substr(plssrange, idx, 4))             
  
  plss       = paste0(plsstownship,"0", plssrange, "0SN", plsssection, "0")
  # 13 digit plss
  idx <- nchar(dd_plss) == 13 | nchar(dms_plss) == 13 | nchar(utm_plss) == 13 | nchar(dd_plss) == 14 | nchar(dms_plss) == 14 | nchar(utm_plss) == 14
  plss2      = ifelse(idx, gsub("SN", "S", plss), plss)
  plss2      = ifelse(idx, paste0(substr(plss2, 1, 12), as.integer(substr(plss2, 13, 14))), plss2)
  plss       = ifelse(idx, plss2, plss)
  # # 14 digit plss
  # idx <- nchar(dd_plss) == 14 | nchar(dms_plss) == 14 | nchar(utm_plss) == 14
  # plss       = ifelse(idx, substr(plss, 1, 14), plss)
  # NA values
  plss       = ifelse(grepl("NA", plss), NA, plss)
})

vars <- c("dd_plss", "dms_plss", "utm_plss")
so[vars] <- lapply(so[vars], function(x) ifelse(x == "NA", NA, x))



## match db vs gis ----
vars <- c("nasissitename", "siteiid", "peiid", "n", "decade", "xy", "ecosite_mlra")
so_lo <- rbind(
  # DD
  cbind(so[vars], overlap = "state",  db = so$state,          dd_gis = so$dd_STUSPS,       dms_gis = so$dms_STUSPS,      utm_gis  = so$utm_STUSPS),
  cbind(so[vars], overlap = "county", db = so$county,         dd_gis = so$dd_countyfp,     dms_gis = so$dms_countyfp,    utm_gis  = so$utm_countyfp),
  cbind(so[vars], overlap = "ssa",    db = so$nonmlrassaarea, dd_gis = so$dd_AREASYMBOL,   dms_gis = so$dms_AREASYMBOL,  utm_gis  = so$utm_AREASYMBOL),
  cbind(so[vars], overlap = "mlra42l", db = so$mlra,           dd_gis = so$dd_MLRARSYM_42,  dms_gis = so$dms_MLRARSYM_42, utm_gis  = so$utm_MLRARSYM_42),
  cbind(so[vars], overlap = "mlra52l", db = so$mlra,           dd_gis = so$dd_MLRARSYM_52,  dms_gis = so$dms_MLRARSYM_52, utm_gis  = so$utm_MLRARSYM_52),
  cbind(so[vars], overlap = "plss",   db = so$plss,           dd_gis = so$dd_plss,         dms_gis = so$dms_plss,        utm_gis = so$utm_plss),
  cbind(so[vars], overlap = "mlra42c",db = so$mlra,           dd_gis = so$dd_mlra42_dom,         dms_gis = so$dms_mlra42_dom, utm_gis = so$utm_mlra42_dom),
  cbind(so[vars], overlap = "mlra52c",db = so$mlra,           dd_gis = so$dd_mlra52_dom,         dms_gis = so$dms_mlra52_dom, utm_gis = so$utm_mlra52_dom)
  
  # # DMS
  # cbind(so[vars], overlap = "dms_state",  db = so$state,          gis = so$dms_STUSPS),
  # cbind(so[vars], overlap = "dms_county", db = so$county,         gis = so$dms_countyfp),
  # cbind(so[vars], overlap = "dms_ssa",    db = so$nonmlrassaarea, gis = so$dms_AREASYMBOL),
  # cbind(so[vars], overlap = "dms_mlra42", db = so$mlra,           gis = so$dms_MLRARSYM_42),
  # cbind(so[vars], overlap = "dms_mlra52", db = so$mlra,           gis = so$dms_MLRARSYM_52),
  # 
  # # UTM
  # cbind(so[vars], overlap = "utm_state",  db = so$state,          gis = so$utm_STUSPS),
  # cbind(so[vars], overlap = "utm_county", db = so$county,         gis = so$utm_countyfp),
  # cbind(so[vars], overlap = "utm_ssa",    db = so$nonmlrassaarea, gis = so$utm_AREASYMBOL),
  # cbind(so[vars], overlap = "utm_mlra42", db = so$mlra,           gis = so$utm_MLRARSYM_42),
  # cbind(so[vars], overlap = "utm_mlra52", db = so$mlra,           gis = so$utm_MLRARSYM_52)
)


# # match all example
# x = 1:3; y = 1:3; df = data.frame(x, y, y)
# rowSums(df$x == df[2:3]) == rowSums(!is.na(df[2:3]))


# replace "NA NA" values with NA
vars <- c("dd_gis", "dms_gis", "utm_gis")
so_lo[vars] <- lapply(so_lo[vars], function(x) ifelse(x == "NA NA", NA, x))

so_lo <- within(so_lo, {
  n_db      = !is.na(db)
  n_gis     = !is.na(dd_gis) | !is.na(dms_gis) | !is.na(utm_gis)
  n_dbgis  = n_db & n_gis
  n_db.mis  = !n_db
  n_gis.mis = !n_gis
  n_dbgis.mis = !n_db & !n_gis
  n_db.mis_gis = !n_db &  n_gis
  n_gis.mis_db = !n_gis & n_db
  n_gis.mis_xy = !n_gis &  xy
  # match0     = db == dd_gis # & n_db
  # nomatch   = !match
  # test = rowSums(!is.na(cbind(dd_gis, dms_gis, utm_gis)), na.rm = TRUE)
  match     = round(rowSums(db == cbind(dd_gis, dms_gis, utm_gis), na.rm = TRUE) / rowSums(!is.na(cbind(dd_gis, dms_gis, utm_gis)), na.rm = TRUE), 2)
  match  = ifelse(is.na(db), NA, match)
  # nomatch = round(rowSums(db!= cbind(dd_gis, dms_gis, utm_gis), na.rm = TRUE) / rowSums(!is.na(cbind(dd_gis, dms_gis, utm_gis)), na.rm = TRUE), 2)
  # nomatch  = ifelse(is.na(db), NA, nomatch)
  nomatch = 1 - match
})
# so_lo$id <- 1:nrow(so_lo)
# nomatch2 <- so_lo %>% rowwise(id) %>% mutate(nomatch = sum(db != cbind(dd_gis, dms_gis, utm_gis)))


aggregate(cbind(
  n, n_db, n_gis, 
  # n_dbgis, n_db.mis, n_gis.mis, 
  n_db.mis_gis, n_gis.mis_db, n_dbgis.mis, 
  # n_gis.mis_xy, 
  nomatch, match #, match0
  ) ~ overlap, data = so_lo, FUN = function(x) sum(x, na.rm = TRUE), na.action = na.pass)


aggregate(cbind(
  n, n_db, n_gis, 
  # n_dbgis, n_db.mis, n_gis.mis, 
  n_db.mis_gis, n_gis.mis_db, n_dbgis.mis, 
  # n_dbgis.mis, n_gis.mis_xy, 
  nomatch, match
  ) ~ nasissitename + overlap, data = so_lo, FUN = function(x) sum(x, na.rm = TRUE), na.action = na.pass)


nm <- names(so_lo)
vars <- nm[! grepl("^n|nomatch", nm)]
test2 <- reshape(
  so_lo[vars],
  direction = "wide",
  idvar = "siteiid",
  v.names = c("match", "db", "dd_gis", "dms_gis", "utm_gis"),
  timevar = "overlap"
)
# idx <- which(names(so) %in% c("peiid", "decade", "xy"))
idx <- c(1:4, 6:10, 21:41, 51:60)
test3 <- merge(test2, so[idx], by = "siteiid", all.y = TRUE)
test3 <- within(test3, {
  lat = y_std
  lon = x_std
})

test3_sf <- st_as_sf(
  test3[test3$xy == TRUE, ],
  coords = c("lon", "lat"),
  crs = 4326
)

idx <- which(sapply(test3_sf, is.logical))
# .gpkg don't like factors
test3_sf[idx] <- lapply(st_drop_geometry(test3_sf[idx]), as.character)
names(test3_sf) <- gsub("\\.", "_", names(test3_sf))
write_sf(test3_sf, "nasis-sites_20221117_qa.gpkg", delete_dsn = TRUE)



# rank matches ----
so <- read_sf("nasis-sites_20221117_qa.gpkg")

idx <- grepl("gis_", names(so))
names(so)[idx] <- gsub("gis_", "", names(so)[idx])

wts <- data.frame(
  usiteid_fip  = 0.375,
  upedonid_fip = 0.375,
  usiteid_ssa  = 0.375,
  upedonid_ssa = 0.375,
  db_county = 0.7,
  dd_ssa    = 0.8, 
  dd_state  = 0.3333333,
  dd_mlra42 = 0.3333333, 
  dd_mlra52 = 0.3333333,
  dd_plss = 1
)[rep(1, times = nrow(so)), ]


so <- within(so, {
  dd_rank = round(rowSums(cbind(
    dd_county == usiteid_fip,
    dd_county == usiteid_ssa,
    dd_county == upedonid_fip,
    dd_county == upedonid_ssa,
    dd_county == db_county,
    dd_ssa    == db_ssa,
    dd_state  == db_state, 
    dd_mlra42l == db_mlra42l,
    dd_mlra52l == db_mlra52l,
    dd_plss   == db_plss
    ) * wts, na.rm = TRUE), 2)
  dms_rank = round(rowSums(cbind(
    dms_county == usiteid_fip,
    dms_county == usiteid_ssa,
    dms_county == upedonid_fip,
    dms_county == upedonid_ssa,
    dms_county == db_county,
    dms_ssa    == db_ssa,
    dms_state  == db_state, 
    dms_mlra42l == db_mlra42l,
    dms_mlra52l == db_mlra52l,
    dms_plss   == db_plss
  ) * wts, na.rm = TRUE), 2)
  utm_rank = round(rowSums(cbind(
    utm_county == usiteid_fip,
    utm_county == usiteid_ssa,
    utm_county == upedonid_fip,
    utm_county == upedonid_ssa,
    utm_county == db_county,
    utm_ssa    == db_ssa,
    utm_state  == db_state, 
    utm_mlra42l == db_mlra42l,
    utm_mlra52l == db_mlra52l,
    utm_plss   == db_plss
  ) * wts, na.rm = TRUE), 2)
  xy_rank = rowSums(cbind(
    complete.cases(x_std, y_std), 
    complete.cases(x_dms, y_dms),
    complete.cases(x_utm, y_utm)
  ), na.rm = TRUE)
})


vars <- c("dd_rank", "dms_rank", "utm_rank")
idx <- max.col(as.matrix(st_drop_geometry(so[vars])), ties.method = "first")
so$xy_max   <- gsub("_rank", "", names(so[vars])[idx])
so$rank_max <- apply(st_drop_geometry(so[vars]), 1, max, na.rm = TRUE)
so$rank_sum <- apply(st_drop_geometry(so[vars]), 1, sum, na.rm = TRUE)


vars <- c("dd_rank", "dms_rank", "utm_rank", "rank_max", "rank_sum")
vars2 <- c("usiteid_fip", "usiteid_ssa", "upedonid_fip", "upedonid_ssa", "db_county", "db_ssa", "db_state", "db_mlra42l", "db_mlra52l", "db_plss")
idx  <- which(names(so) %in% vars)
so[idx] <- lapply(st_drop_geometry(so[idx]), function(x) {
  ifelse(
    # x = 0 & all vars are not NA
    x < 0.1 & rowSums(is.na(st_drop_geometry(so[vars2]))) == length(vars2),
    -1,
    x
  )
})


test <- (so[idx > 1 & idx < 2 & (!is.na(so$db_county)), c("id", vars)])
paste0(sample(test$id, 100), collapse = ", ")

so2 <- so[c(1:2, 75:84, 86:92, 3:74, 85)]
write_sf(so2, dsn = "nasis-sites_20221103_qa2.gpkg")


## select best xy ----
so2 <- read_sf(dsn = "nasis-sites_20221103_qa2.gpkg")

idx <- so2$xy_max == cbind("dd", "dms", "utm")[rep(1, nrow(so2)), ]
mlra <- as.matrix(st_drop_geometry(so2[55:57]))
idx  <- as.matrix(data.frame(1:nrow(so2), max.col(idx)))
mlra <- mlra[idx]

round(prop.table(table(so2$ecosite_mlra == mlra)), 2)
round(prop.table(table(so2$ecosite_mlra == so2$dd_mlra42l)), 2)
round(prop.table(table(so2$ecosite_mlra == so2$dd_mlra42c)), 2)
round(prop.table(table(mlra == so2[[55]])), 2)


# decision tree ----
## overlaps ----
# if db_county != usiteid_fip & coordinates %in% c(db_county, usiteiid) then select match with the most coordinates
# if overlaps != coordinates, but all coordinates match
# if coordinates != db_county & distance < 100m

## coordinates ----
# all geocoordsource %in% c(autopopulated, imported) do not have issues
# if all(rowMean(coordinates) !== cbind(coordinates)) then select coordinates that match db_county 
# if db_county == usiteid_fip & ! coordinates %in% c(db_county, usiteid_fip) & db_plss != coordinates, flag the coordinates as BAD
# utm x!=y Alena found examples of this!

# upload the qa results as a separate table, or add to all the pedons


